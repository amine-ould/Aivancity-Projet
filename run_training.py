#!/usr/bin/env python
"""
Script simple pour lancer l'entra√Ænement des mod√®les.
Utilise les donn√©es nettoy√©es d'extract.py et clean.py
üéØ Avec suivi WandB pour l'exp√©rience tracking
‚ö° Avec barre de progression et optimisation de temps
"""

import os
import sys
from pathlib import Path
import json
from datetime import datetime
import time
import logging
from tqdm import tqdm

# üîá R√©duire la verbosit√© des logs pendant l'entra√Ænement
logging.getLogger('models.train_model').setLevel(logging.WARNING)
logging.getLogger('lightgbm').setLevel(logging.WARNING)
logging.getLogger('xgboost').setLevel(logging.WARNING)

# Charger la configuration WandB
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'wandb'))
from wandb_config import load_wandb_config
load_wandb_config()

import wandb
from wandb_metrics_logger import WandBMetricsLogger

# Ajouter le chemin du dossier src pour les imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from models.train_model import train_and_evaluate

# === CONFIGURATION √Ä MODIFIER SELON VOS BESOIN S ===

# 1. ‚úÖ CHEMIN DE DONN√âES - √Ä REMPLACER PAR VOTRE FICHIER PR√âTRAIT√â
# Le fichier doit √™tre un CSV avec une colonne 'failure_within_24h' (la cible)
DATA_PATH = r"data\processed\cleaned_data\sensor_data_cleaned.csv"  # √Ä ADAPTER!

# 2. ‚úÖ R√âPERTOIRE POUR SAUVEGARDER LES MOD√àLES
MODELS_DIR = os.path.join("src", "models", "models")

# 3. ‚úÖ COLONNE CIBLE (column with 0s and 1s for failure/no failure)
TARGET_COLUMN = "failure_within_24h"

# 4. ‚úÖ PARAM√àTRES D'ENTRA√éNEMENT
TEST_SIZE = 0.2  # 20% pour test, 80% pour train
RANDOM_STATE = 42  # Pour reproductibilit√©
CV = 3  # ‚ö° R√©duit de 5 √† 3 pour la vitesse (minimal pour la validit√© statistique)

# 5. ‚úÖ QUELS MOD√àLES ENTRA√éNER? (laissez None pour tous)
# Options: ["random_forest", "gradient_boosting", "logistic_regression", "xgboost", "lightgbm"]
# Mettez None ou [] pour entra√Æner TOUS les mod√®les
# ‚ö° OPTIMIS√â: Entra√Æner les mod√®les rapides par d√©faut
MODELS_TO_TRAIN = ["random_forest", "gradient_boosting", "logistic_regression", "xgboost", "lightgbm"]  # ‚ö° Rapides seulement (3-5 min)

# 6. ‚úÖ CONFIGURATION WANDB
WANDB_CONFIG = {
    "project": "industrial-failure-prediction",  # Changez le nom du projet
    "entity": "ouldamroucheamine-aivancity-school-for-technology-busine",  # Workspace WandB
    "enable_wandb": True,  # Mettez False pour d√©sactiver WandB temporairement
    "tags": ["training", "production"],
    "notes": "Entra√Ænement complet avec tous les mod√®les"
}

# ============================================================

if __name__ == "__main__":
    # ‚è±Ô∏è D√©marrer le chrono
    start_time = time.time()
    
    print("\n" + "="*60)
    print("‚ö° PIPELINE D'ENTRA√éNEMENT OPTIMIS√â")
    print("="*60 + "\n")
    
    # V√©rifier que le fichier de donn√©es existe
    if not os.path.exists(DATA_PATH):
        print(f"‚ùå ERREUR: Le fichier de donn√©es n'existe pas: {DATA_PATH}")
        print(f"\nConseil: V√©rifiez que:")
        print("  1. Vous avez ex√©cut√© extract.py (extrait les donn√©es brutes)")
        print("  2. Vous avez ex√©cut√© clean.py (nettoie les donn√©es)")
        print("  3. Le chemin DATA_PATH est correct")
        print(f"\nChemin attendu: {os.path.abspath(DATA_PATH)}")
        sys.exit(1)
    
    # Cr√©er le r√©pertoire pour les mod√®les s'il n'existe pas
    os.makedirs(MODELS_DIR, exist_ok=True)
    
    print(f"‚úÖ Fichier de donn√©es: {os.path.abspath(DATA_PATH)}")
    print(f"‚úÖ R√©pertoire de sortie: {os.path.abspath(MODELS_DIR)}")
    print(f"‚ö° Validation crois√©e: {CV}-fold (optimis√©)")
    print(f"‚ö° Mod√®les rapides uniquement")
    print(f"‚úÖ Mod√®les √† entra√Æner: {MODELS_TO_TRAIN if MODELS_TO_TRAIN else 'TOUS'}")
    print(f"‚úÖ Train/Test split: {(1-TEST_SIZE)*100:.0f}% / {TEST_SIZE*100:.0f}%")
    print(f"‚úÖ Validation crois√©e: {CV}-fold\n")
    
    # === INITIALISER WANDB ===
    wandb_run = None
    data_for_logging = None
    if WANDB_CONFIG.get("enable_wandb", True):
        try:
            wandb_run = wandb.init(
                project=WANDB_CONFIG["project"],
                entity=WANDB_CONFIG.get("entity"),
                tags=WANDB_CONFIG.get("tags", []),
                notes=WANDB_CONFIG.get("notes", ""),
                config={
                    "data_path": DATA_PATH,
                    "target_column": TARGET_COLUMN,
                    "test_size": TEST_SIZE,
                    "random_state": RANDOM_STATE,
                    "cv_folds": CV,
                    "models_to_train": MODELS_TO_TRAIN if MODELS_TO_TRAIN else "ALL"
                }
            )
            print(f"üéØ WandB initialis√©: {wandb_run.get_url()}\n")

            # ===== Logs dataset & contexte (pertinent avant entra√Ænement) =====
            try:
                import pandas as pd
                import numpy as np
                import matplotlib.pyplot as plt
                import seaborn as sns
                data_for_logging = pd.read_csv(DATA_PATH)

                # Config enrichie
                wandb.config.update({
                    "data_rows": int(data_for_logging.shape[0]),
                    "data_cols": int(data_for_logging.shape[1]),
                    "features_count": int(data_for_logging.shape[1] - 1),
                }, allow_val_change=True)

                # Artifact dataset
                dataset_artifact = wandb.Artifact(
                    name="predictive_maintenance_dataset",
                    type="dataset",
                    description="Dataset pr√©trait√© utilis√© pour l'entra√Ænement",
                    metadata={
                        "rows": int(data_for_logging.shape[0]),
                        "cols": int(data_for_logging.shape[1]),
                        "target_column": TARGET_COLUMN
                    }
                )
                dataset_artifact.add_file(DATA_PATH)
                wandb_run.log_artifact(dataset_artifact)

                # √âchantillon du dataset
                wandb.log({"data/sample": wandb.Table(dataframe=data_for_logging.head(200))})

                # Taux de valeurs manquantes (Top 30)
                missing_rate = data_for_logging.isnull().mean().sort_values(ascending=False)
                missing_df = missing_rate.head(30).reset_index()
                missing_df.columns = ["feature", "missing_rate"]
                wandb.log({"data/missing_rate": wandb.Table(dataframe=missing_df)})

                # Statistiques descriptives
                desc_df = data_for_logging.describe(include="all").transpose().reset_index()
                desc_df.columns = ["feature"] + [c if c else "value" for c in desc_df.columns[1:]]
                wandb.log({"data/describe": wandb.Table(dataframe=desc_df)})

                # Heatmap corr√©lation (features num√©riques)
                numeric_df = data_for_logging.select_dtypes(include=[np.number])
                if TARGET_COLUMN in numeric_df.columns:
                    numeric_df = numeric_df.drop(columns=[TARGET_COLUMN])
                if numeric_df.shape[1] > 1:
                    corr = numeric_df.corr()
                    fig, ax = plt.subplots(figsize=(10, 8))
                    sns.heatmap(corr, cmap="coolwarm", center=0, ax=ax)
                    ax.set_title("Correlation Heatmap (features num√©riques)")
                    wandb.log({"data/correlation_heatmap": wandb.Image(fig)})
                    plt.close(fig)

                # Distribution cible
                if TARGET_COLUMN in data_for_logging.columns:
                    target_counts = data_for_logging[TARGET_COLUMN].value_counts()
                    target_ratio = data_for_logging[TARGET_COLUMN].value_counts(normalize=True)
                    wandb.log({
                        "data/target_pos": int(target_counts.get(1, 0)),
                        "data/target_neg": int(target_counts.get(0, 0)),
                        "data/target_pos_rate": float(target_ratio.get(1, 0)),
                        "data/target_neg_rate": float(target_ratio.get(0, 0))
                    })

                    # Bar chart distribution cible
                    fig, ax = plt.subplots(figsize=(6, 4))
                    ax.bar(["neg", "pos"], [int(target_counts.get(0, 0)), int(target_counts.get(1, 0))], color=["#4C78A8", "#F58518"])
                    ax.set_title("Distribution de la cible")
                    ax.set_ylabel("Count")
                    wandb.log({"data/target_distribution": wandb.Image(fig)})
                    plt.close(fig)
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible de logger les infos dataset dans WandB: {e}")
        except Exception as e:
            print(f"‚ö†Ô∏è WandB non disponible: {e}")
            print("  L'entra√Ænement continue sans WandB...\n")
    
    try:
        # üìä √âtape 1: Lancer l'entra√Ænement (avec barre de progression temps r√©el)
        import threading
        from queue import Queue
        
        training_state = {'status': 'en cours', 'start_time': time.time()}
        
        def update_progress_bar():
            """Barre de progression bas√©e sur le temps + mod√®les compl√©t√©s"""
            # Estimation: ~6 min pour 3 mod√®les (XGBoost 2-3min, LightGBM 2-3min, LogReg 30s)
            estimated_time = 360  # 6 minutes en secondes
            
            with tqdm(total=100, desc="‚öôÔ∏è Entra√Ænement", 
                     bar_format='{l_bar}{bar}| {n_fmt}% | {elapsed}s') as pbar:
                last_percentage = 0
                
                while training_state['status'] == 'en cours':
                    elapsed = time.time() - training_state['start_time']
                    
                    # Calcul du pourcentage: 0-95% pendant l'entra√Ænement, 95-100% √† la fin
                    percentage = min(95, int((elapsed / estimated_time) * 95))
                    
                    if percentage > last_percentage:
                        pbar.update(percentage - last_percentage)
                        last_percentage = percentage
                    
                    time.sleep(1)  # Mise √† jour chaque seconde
                
                # Compl√©ter √† 100%
                if last_percentage < 100:
                    pbar.update(100 - last_percentage)
        
        # Lancer le thread de progression
        progress_thread = threading.Thread(target=update_progress_bar, daemon=True)
        progress_thread.start()
        
        # Lancer l'entra√Ænement
        trained_models, evaluation_results, model_paths, best_model = train_and_evaluate(
            data_path=DATA_PATH,
            target_column=TARGET_COLUMN,
            models_to_train=MODELS_TO_TRAIN,
            models_dir=MODELS_DIR,
            test_size=TEST_SIZE,
            cv=CV,
            use_wandb=True,
            wandb_run=wandb_run
        )
        
        # Signal que l'entra√Ænement est fini
        training_state['status'] = 'termin√©'
        progress_thread.join(timeout=2)
        
        # ‚è±Ô∏è Calculer le temps total
        elapsed_time = time.time() - start_time
        
        print("\n" + "="*60)
        print("‚úÖ ENTRA√éNEMENT R√âUSSI!")
        print("="*60)
        print(f"\n‚è±Ô∏è  Temps total: {elapsed_time:.2f}s ({elapsed_time/60:.2f} min)\n")
        
        print(f"‚úÖ Mod√®les entra√Æn√©s: {list(trained_models.keys())}")
        print(f"‚úÖ Sauvegard√©s dans: {os.path.abspath(MODELS_DIR)}\n")
        
        # üìä √âtape 2: Logger les m√©triques d√©taill√©es dans WandB
        print("üìä Logging des m√©triques d√©taill√©es...\n")
        
        if wandb_run:
            # Charger les donn√©es pour feature importance et drift
            if data_for_logging is None:
                import pandas as pd
                data = pd.read_csv(DATA_PATH)
            else:
                data = data_for_logging
            from sklearn.model_selection import train_test_split
            X = data.drop(columns=[TARGET_COLUMN])
            y = data[TARGET_COLUMN]
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y
            )
            
            # Logger les m√©triques pour chaque mod√®le
            for model_name, model_info in tqdm(trained_models.items(), desc="Logging mod√®les",
                                               bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}'):
                model = model_info['model']
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1]
                
                # M√©triques d√©taill√©es
                WandBMetricsLogger.log_model_metrics(model_name, y_test, y_pred, y_pred_proba, model)
                
                # Feature importance
                WandBMetricsLogger.log_feature_importance(
                    model_name, model, list(X_train.columns), top_n=15
                )
                
                # Hyperparam√®tres
                if 'params' in model_info:
                    WandBMetricsLogger.log_hyperparameters(model_name, model_info['params'])
            
            # Data drift
            try:
                WandBMetricsLogger.log_data_drift(list(X_train.columns), X_train, X_test)
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible de logger drift: {e}")
            
            # Comparaison des mod√®les
            WandBMetricsLogger.log_model_comparison(evaluation_results)

            # Tableau de synth√®se des m√©triques
            try:
                import pandas as pd
                summary_rows = []
                for model_name, eval_info in evaluation_results.items():
                    summary_rows.append({
                        "model": model_name,
                        "accuracy": float(eval_info.get("accuracy", 0)),
                        "auc": float(eval_info.get("auc", 0)),
                        "recall": float(eval_info.get("recall", 0)),
                        "precision": float(eval_info.get("precision", 0)),
                        "f1": float(eval_info.get("f1", 0))
                    })
                summary_df = pd.DataFrame(summary_rows)
                wandb.log({"results/summary_table": wandb.Table(dataframe=summary_df)})
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible de logger le tableau de synth√®se: {e}")
            
            print("‚úÖ M√©triques enregistr√©es dans WandB\n")
        
        # üìä √âtape 3: Afficher le r√©sum√©
        print("R√âSUM√â DES PERFORMANCES:")
        print("-" * 50)
        
        for model_name, eval_info in tqdm(evaluation_results.items(), desc="R√©sultats", 
                                         bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}'):
            print(f"\n{model_name.upper()}")
            print(f"  ‚úÖ Accuracy:  {eval_info['accuracy']:.4f}")
            print(f"  ‚úÖ AUC ROC:   {eval_info['auc']:.4f}")
        
        # üì§ √âtape 4: Finalize WandB
        if wandb_run:
            print("\n‚úÖ R√©sultats enregistr√©s dans WandB")
            try:
                wandb.config.update({
                    "best_model": best_model,
                    "elapsed_seconds": float(elapsed_time)
                }, allow_val_change=True)
                wandb.log({"training/elapsed_seconds": float(elapsed_time)})
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible de logger le temps d'entra√Ænement: {e}")
            wandb.finish()
        
        print("\n‚úÖ Les fichiers features_importance ont √©galement √©t√© sauvegard√©s.")
        print("   Utilisez-les pour comprendre quelles caract√©ristiques sont les plus importantes.")
        print(f"\n‚è±Ô∏è  Temps total: {elapsed_time:.2f}s ({elapsed_time/60:.2f} min)\n")
        
    except Exception as e:
        print(f"\n‚ùå ERREUR lors de l'entra√Ænement: {e}")
        import traceback
        traceback.print_exc()
        if wandb_run:
            wandb.finish(exit_code=1)
        sys.exit(1)
