# ğŸ¤– GUIDE D'ENTRAÃNEMENT DU MODÃˆLE

## ğŸ“‹ RÃ©sumÃ© du Code

Ton projet contient un **pipeline ML complet** pour prÃ©dire les dÃ©faillances d'Ã©quipements:

```
DONNÃ‰ES BRUTES
     â†“
[1] EXTRACTION (extract.py) â†’ Charge les CSV des capteurs et dÃ©faillances
     â†“
[2] NETTOYAGE (clean.py) â†’ Supprime les doublons, gÃ¨re les NaN, outliers
     â†“
[3] FEATURES (build_features.py) â†’ CrÃ©e variables polynomiales, cycles
     â†“
[4] ENTRAÃNEMENT â­ (train_model.py) â†’ EntraÃ®ne 5 modÃ¨les diffÃ©rents
     â†“
[5] MODÃˆLES SAUVEGARDÃ‰S â†’ Ã€ utiliser pour prÃ©dictions futures
```

---

## ğŸ”´ Les 3 ProblÃ¨mes qu'il y Avait

### âŒ **ProblÃ¨me #1: ModÃ¨les CPU manquants (ligne 96)**
```python
# AVANT (incomplÃ¨te):
self.models = { }

# APRÃˆS (corrigÃ©e) âœ…:
self.models = {
    'random_forest': {...},
    'gradient_boosting': {...},
    'logistic_regression': {...},
    'xgboost': {...},
    'lightgbm': {...}
}
```

### âŒ **ProblÃ¨me #2: MÃ©triques d'Ã©valuation incomplÃ¨tes (ligne 238)**
```python
# AVANT (incomplet):
accuracy = 
conf_matrix = 
class_report = 
auc_score = 

# APRÃˆS (corrigÃ©e) âœ…:
accuracy = (y_pred == y_test).astype(int).mean()
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
auc_score = roc_auc_score(y_test, y_pred_proba)
```

### âŒ **ProblÃ¨me #3: Fonction `find_best_model()` incomplÃ¨te**
```python
# AVANT (incomplet):
scores =   # â† vide!
best_model = 

# APRÃˆS (corrigÃ©e) âœ…:
scores = {model: eval_info[metric] for model, eval_info in evaluation_results.items()}
best_model = max(scores, key=scores.get)
```

**Tous les problÃ¨mes ont Ã©tÃ© corrigÃ©s! âœ…**

---

## ğŸš€ Comment Lancer l'EntraÃ®nement

### Ã‰tape 1: PrÃ©parer les donnÃ©es
Avant l'entraÃ®nement, tu dois avoir des donnÃ©es nettoyÃ©es. ExÃ©cute dans cet ordre:

```bash
# 1. Extraire les donnÃ©es brutes
python src/data/extract.py

# 2. Nettoyer les donnÃ©es
python src/data/clean.py

# 3. CrÃ©er les features (optionnel si dÃ©jÃ  fait)
python src/features/build_features.py
```

**âš ï¸ IMPORTANT:** Ã€ la fin, tu dois avoir un fichier CSV avec:
- Colonnes de features (temperature, vibration, pressure, current, etc.)
- Une colonne `failure_within_24h` (0 ou 1) = LA CIBLE

### Ã‰tape 2: Ã‰diter `run_training.py`

Ouvre le fichier `run_training.py` et change ces lignes:

```python
# âœ… Ã€ MODIFIER - Chemin vers votre fichier prÃ©traitÃ©
DATA_PATH = r"data\processed\cleaned_data\VOTRE_FICHIER.csv"

# âœ… Les autres paramÃ¨tres (facultatif)
TEST_SIZE = 0.2  # 80% train, 20% test
TARGET_COLUMN = "failure_within_24h"  # â† Colonne de prÃ©diction
MODELS_TO_TRAIN = None  # Laissez None pour tous, ou ["random_forest", "xgboost"]
```

### Ã‰tape 3: Lancer l'entraÃ®nement

```bash
python run_training.py
```

**Ou avec la ligne de commande (avancÃ©):**

```bash
python -m src.models.train_model --data_path "chemin/donnees.csv" \
                                  --target_column "failure_within_24h" \
                                  --models random_forest xgboost
```

---

## ğŸ“Š Quels ModÃ¨les Sont EntraÃ®nÃ©s?

Le code entraÃ®ne **5 modÃ¨les diffÃ©rents**:

| ModÃ¨le | Description | Temps | Performance |
|--------|-------------|-------|-------------|
| **Random Forest** ğŸŒ²ğŸŒ² | Ensemble de 300 arbres | Moyen | TrÃ¨s bon |
| **Gradient Boosting** ğŸ“ˆ | Boosting des arbres | Lent | Excellent |
| **Logistic Regression** ğŸ“Š | RÃ©gression linÃ©aire | Rapide | Bon |
| **XGBoost** âš¡ | Boosting GPU-ready | Rapide | Excellent |
| **LightGBM** ğŸ’¡ | Boosting lÃ©ger | Super rapide | Excellent |

---

## ğŸ“ OÃ¹ Sont SauvegardÃ©s les ModÃ¨les?

AprÃ¨s l'entraÃ®nement, tu trouveras:

```
src/models/models/
â”œâ”€â”€ random_forest_20250114_143022.pkl
â”œâ”€â”€ xgboost_20250114_143022.pkl
â”œâ”€â”€ random_forest_feature_importance_20250114_143022.csv
â”œâ”€â”€ xgboost_feature_importance_20250114_143022.csv
â””â”€â”€ training_summary_20250114_143022.pkl
```

**Fichiers crÃ©Ã©s:**
- `*.pkl` = Le modÃ¨le complet (poids + paramÃ¨tres)
- `*_feature_importance.csv` = Quelles features sont les plus importantes
- `training_summary_*.pkl` = RÃ©sumÃ© de tous les rÃ©sultats

---

## ğŸ” Que Fait Exactement le Code?

### 1ï¸âƒ£ **Load Data** (`load_data()`)
```python
Charge le fichier CSV prÃ©traitÃ© dans un DataFrame Pandas
```

### 2ï¸âƒ£ **Prepare Train/Test** (`prepare_train_test_data()`)
```python
- SÃ©pare X (features) et y (target)
- Divise: 80% entraÃ®nement, 20% test
- Remplace NaN/Inf par 0
- Affiche distribution des classes
```

### 3ï¸âƒ£ **Train Models** (`train_models()`)
```python
Pour chaque modÃ¨le:
  â”œâ”€ GridSearchCV pour trouver les meilleurs paramÃ¨tres
  â”œâ”€ Essaie 50+ combinaisons de paramÃ¨tres
  â”œâ”€ Utilise 5-fold cross-validation
  â””â”€ Garde le meilleur modÃ¨le
```

### 4ï¸âƒ£ **Evaluate** (`evaluate_models()`)
```python
Pour chaque modÃ¨le entraÃ®nÃ©:
  â”œâ”€ Fait des prÃ©dictions sur le test set
  â”œâ”€ Calcule: Accuracy, Precision, Recall, AUC, F1
  â”œâ”€ CrÃ©e matrice de confusion
  â””â”€ Affiche un rapport dÃ©taillÃ©
```

### 5ï¸âƒ£ **Save** (`save_models()`)
```python
- Sauvegarde modÃ¨les dans .pkl
- Sauvegarde l'importance des features
- CrÃ©e un fichier rÃ©sumÃ©
```

---

## âš™ï¸ PARAMÃˆTRES Ã€ MODIFIER

Dans `run_training.py`, tu peux changer:

```python
# 1. Quel fichier de donnÃ©es utiliser?
DATA_PATH = "..."  # Chemin Ã  ta donnÃ©e nettoyÃ©e

# 2. Train/Test split
TEST_SIZE = 0.2  # De 0 Ã  1 (plus grand = plus de donnÃ©es pour test)

# 3. Colonne cible
TARGET_COLUMN = "failure_within_24h"  # Doit Ãªtre 0 ou 1

# 4. ModÃ¨les Ã  entraÃ®ner (None = tous)
MODELS_TO_TRAIN = ["random_forest", "xgboost"]  # ou None

# 5. Validation croisÃ©e
CV = 5  # Nombre de folds (5 = classique)

# 6. Graine alÃ©atoire
RANDOM_STATE = 42  # Pour reproductibilitÃ©
```

---

## ğŸš¨ Erreurs Courantes et Solutions

### âŒ "FileNotFoundError: No such file"
**Solution:** VÃ©rifiez que DATA_PATH pointe vers un fichier qui existe.
```python
# Lisez d'abord votre dossier
import os
print(os.listdir("data/processed/cleaned_data/"))
```

### âŒ "KeyError: 'failure_within_24h'"
**Solution:** La colonne cible n'existe pas. Changez TARGET_COLUMN:
```python
# VÃ©rifiez les colonnes disponibles
df = pd.read_csv(DATA_PATH)
print(df.columns.tolist())
```

### âŒ "ValueError: Invalid parameter..."
**Solution:** Un paramÃ¨tre n'est pas valide. VÃ©rifiez MODELS_TO_TRAIN:
```python
# ModÃ¨les valides:
["random_forest", "gradient_boosting", "logistic_regression", "xgboost", "lightgbm"]
```

### âŒ "MemoryError" - pas assez de mÃ©moire
**Solution:** RÃ©duisez TEST_SIZE ou utilisez une partie des donnÃ©es.

---

## ğŸ“ˆ InterprÃ©ter les RÃ©sultats

AprÃ¨s l'entraÃ®nement, tu verras:

```
RÃ‰SUMÃ‰ DES PERFORMANCES:
--------------------------------------------------

RANDOM_FOREST
  Accuracy: 0.8932  â† Combien de prÃ©dictions justes (0-1)
  AUC:      0.9234  â† Meilleur = 1.0

XGBOOST
  Accuracy: 0.9045
  AUC:      0.9456

...
```

**Guide d'interprÃ©tation:**
- **Accuracy > 0.85** = Bon âœ…
- **AUC > 0.85** = Bon âœ…
- **AUC > 0.95** = Excellent ğŸŒŸ

---

## ğŸ¯ Prochaines Ã‰tapes

1. **Entrainez les modÃ¨les** avec `run_training.py`
2. **Utilisez `predict_model.py`** pour faire des prÃ©dictions sur nouvelles donnÃ©es
3. **Trackez les performances** avec `monitoring/performance_tracking.py`
4. **DÃ©tectez la dÃ©rive de donnÃ©es** avec `monitoring/data_drift.py`

---

## ğŸ’¡ Conseils Pro

âœ… **Commencez simple:** EntraÃ®nez d'abord Random Forest (rapide, bon)
âœ… **Testez ensemble:** Puis XGBoost et LightGBM (plus lents, meilleures perf)
âœ… **Sauvegardez tout:** Les modÃ¨les sont dans `src/models/models/`
âœ… **Comparez:** L'importance des features aide Ã  comprendre les prÃ©dictions

---

**C'est prÃªt! Bon entraÃ®nement! ğŸš€**
