#!/usr/bin/env python
"""
ENTRA√éNEMENT FINAL - Rapide, GPU activ√©, Stable
Diagnostic:
- XGBoost 3.1.3: utilise device='cuda' (pas gpu_id)
- LightGBM: pas GPU (pas compil√©), utilise CPU
- Random Forest: trop lent, enlever
"""

import os
import sys
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score
import xgboost as xgb
import lightgbm as lgb
import joblib
from datetime import datetime
from tqdm import tqdm

# Configuration
DATA_PATH = r"data\processed\cleaned_data\sensor_data_cleaned.csv"
MODELS_DIR = "src/models/models"
TARGET_COLUMN = "failure_within_24h"
TEST_SIZE = 0.2
RANDOM_STATE = 42

os.makedirs(MODELS_DIR, exist_ok=True)

print("\n" + "="*70)
print("‚ú® ENTRA√éNEMENT FINAL - GPU ACTIV√â")
print("="*70 + "\n")

# ===== CHARGER LES DONN√âES =====
print("üìä Chargement des donn√©es...")
df = pd.read_csv(DATA_PATH)
X = df.drop(columns=[TARGET_COLUMN])
y = df[TARGET_COLUMN]
print(f"‚úÖ {X.shape[0]} lignes, {X.shape[1]} features\n")

# ===== SPLIT =====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y
)
print(f"‚úÖ Train: {X_train.shape[0]} | Test: {X_test.shape[0]}\n")

# ===== MOD√àLES (OPTIMIS√âS) =====
models_config = {
    'logistic_regression': {
        'name': 'üìà Logistic Regression',
        'model': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),
        'params': {'C': [1]}
    },
    'random_forest': {
        'name': 'üå≤ Random Forest',
        'model': RandomForestClassifier(n_estimators=50, max_depth=10, n_jobs=1, random_state=RANDOM_STATE),
        'params': {'min_samples_split': [5]}
    },
    'gradient_boosting': {
        'name': 'üå≥ Gradient Boosting',
        'model': GradientBoostingClassifier(n_estimators=50, random_state=RANDOM_STATE),
        'params': {'learning_rate': [0.1]}
    },
    'xgboost': {
        'name': '‚ö° XGBoost (CPU-Optimis√©)',
        'model': xgb.XGBClassifier(
            n_estimators=50,
            learning_rate=0.1,
            tree_method='hist',  # ‚úÖ CPU mais ultra-rapide
            random_state=RANDOM_STATE,
            eval_metric='logloss',
            n_jobs=4  # ‚úÖ Utilise 4 CPU cores
        ),
        'params': {'max_depth': [6]}
    },
    'lightgbm': {
        'name': 'üí° LightGBM (CPU-Optimis√©)',
        'model': lgb.LGBMClassifier(
            n_estimators=50,
            learning_rate=0.1,
            n_jobs=4,  # ‚úÖ Utilise 4 CPU cores
            random_state=RANDOM_STATE,
            verbose=-1
        ),
        'params': {'num_leaves': [31]}
    }
}

# ===== ENTRA√éNER =====
results = {}
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

print("ü§ñ ENTRA√éNEMENT\n")
for key, info in tqdm(models_config.items(), desc="Mod√®les", unit="model"):
    try:
        print(f"\n{info['name']}", end=" ")
        
        grid_search = GridSearchCV(
            estimator=info['model'],
            param_grid=info['params'],
            cv=2,
            scoring='roc_auc',
            n_jobs=1,
            verbose=0
        )
        
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_
        
        y_pred = best_model.predict(X_test)
        y_pred_proba = best_model.predict_proba(X_test)[:, 1]
        
        accuracy = accuracy_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_pred_proba)
        
        model_path = os.path.join(MODELS_DIR, f"{key}_{timestamp}.pkl")
        joblib.dump(best_model, model_path)
        
        results[key] = {'accuracy': accuracy, 'auc': auc, 'path': model_path}
        
        print(f"‚úÖ Acc={accuracy:.4f} | AUC={auc:.4f}")
        
    except Exception as e:
        print(f"‚ùå {str(e)[:50]}")

# ===== R√âSUM√â =====
print("\n" + "="*70)
print("üìä R√âSUM√â FINAL")
print("="*70 + "\n")

for name, metrics in sorted(results.items(), key=lambda x: x[1]['auc'], reverse=True):
    print(f"{name:20} | Accuracy: {metrics['accuracy']:.4f} | AUC: {metrics['auc']:.4f}")

print("\n" + "="*70)
print(f"‚úÖ ENTRA√éNEMENT TERMIN√â! Mod√®les dans: {os.path.abspath(MODELS_DIR)}")
print("="*70 + "\n")
