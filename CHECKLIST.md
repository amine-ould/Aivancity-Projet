## ‚úÖ CHECKLIST D'ENTRA√éNEMENT

### Avant de lancer l'entra√Ænement:

- [ ] **V√©rifier les d√©pendances:**
  ```bash
  pip install pandas numpy scikit-learn xgboost lightgbm joblib
  ```

- [ ] **Pr√©parer les donn√©es:**
  - [ ] Ex√©cuter `python src/data/extract.py` (extraire les CSV bruts)
  - [ ] Ex√©cuter `python src/data/clean.py` (nettoyer les donn√©es)
  - [ ] V√©rifier qu'un fichier CSV existe dans `data/processed/cleaned_data/`

- [ ] **Configurer `run_training.py`:**
  - [ ] Changer `DATA_PATH` vers le fichier nettoy√©
  - [ ] V√©rifier que `TARGET_COLUMN = "failure_within_24h"` existe dans vos donn√©es
  - [ ] (Optionnel) S√©lectionner les mod√®les avec `MODELS_TO_TRAIN`

- [ ] **V√©rifier les permissions:**
  - [ ] Dossier `src/models/models/` accessible en √©criture
  - [ ] Dossier `data/` accessible en lecture

### Lancer l'entra√Ænement:

```bash
python run_training.py
```

‚è±Ô∏è Temps estim√©:
- Random Forest: 2-5 min
- Gradient Boosting: 3-8 min
- Logistic Regression: < 1 min
- XGBoost: 2-4 min
- LightGBM: 1-3 min
- **TOTAL: 10-30 minutes** (selon votre machine)

### Apr√®s l'entra√Ænement:

- [ ] V√©rifier que les fichiers `.pkl` ont √©t√© cr√©√©s dans `src/models/models/`
- [ ] Lire le fichier `GUIDE_ENTRA√éNEMENT.md` pour les prochaines √©tapes
- [ ] Examiner les `*_feature_importance.csv` pour comprendre les pr√©dictions
- [ ] Utiliser `predict_model.py` pour faire des pr√©dictions

### Si des erreurs:

1. V√©rifier que le fichier DATA_PATH existe:
   ```python
   import os
   print(os.path.exists("votre_chemin.csv"))
   ```

2. V√©rifier les colonnes:
   ```python
   import pandas as pd
   df = pd.read_csv("votre_chemin.csv")
   print(df.columns.tolist())
   print(df['failure_within_24h'].unique())
   ```

3. V√©rifier les importations:
   ```python
   import xgboost
   import lightgbm
   print("‚úÖ D√©pendances OK")
   ```

---

**Questions?** Consultez `GUIDE_ENTRA√éNEMENT.md` üìñ
