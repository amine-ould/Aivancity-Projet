#!/usr/bin/env python
"""
ENTRA√éNEMENT AVEC GPU NVIDIA - Version optimis√©e
XGBoost avec CUDA, LightGBM optimis√©
"""

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score
import xgboost as xgb
import lightgbm as lgb
import joblib
from datetime import datetime
from tqdm import tqdm

print(f"‚úÖ XGBoost version: {xgb.__version__}")
print(f"‚úÖ LightGBM version: {lgb.__version__}\n")

# Configuration
DATA_PATH = r"data\processed\cleaned_data\sensor_data_cleaned.csv"
MODELS_DIR = "src/models/models"
TARGET_COLUMN = "failure_within_24h"
TEST_SIZE = 0.2
RANDOM_STATE = 42

os.makedirs(MODELS_DIR, exist_ok=True)

print("="*70)
print("üöÄ ENTRA√éNEMENT AVEC GPU NVIDIA")
print("="*70 + "\n")

# ===== CHARGER =====
print("üìä Chargement des donn√©es...")
df = pd.read_csv(DATA_PATH)
X = df.drop(columns=[TARGET_COLUMN])
y = df[TARGET_COLUMN]
print(f"‚úÖ {X.shape[0]} lignes, {X.shape[1]} features\n")

# ===== SPLIT =====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y
)
print(f"‚úÖ Train: {X_train.shape[0]} | Test: {X_test.shape[0]}\n")

# ===== MOD√àLES =====
models_config = {
    'logistic_regression': {
        'name': 'üìà Logistic Regression',
        'model': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),
        'params': {'C': [1]}
    },
    'random_forest': {
        'name': 'üå≤ Random Forest',
        'model': RandomForestClassifier(n_estimators=50, max_depth=10, n_jobs=4, random_state=RANDOM_STATE),
        'params': {'min_samples_split': [5]}
    },
    'gradient_boosting': {
        'name': 'üå≥ Gradient Boosting',
        'model': GradientBoostingClassifier(n_estimators=50, random_state=RANDOM_STATE),
        'params': {'learning_rate': [0.1]}
    },
    'xgboost_gpu': {
        'name': '‚ö° XGBoost (Multi-Thread CPU)',
        'model': xgb.XGBClassifier(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=6,
            tree_method='hist',       # ‚úÖ CPU mais ultra-rapide
            nthread=4,                # ‚úÖ 4 threads
            random_state=RANDOM_STATE,
            eval_metric='logloss'
        ),
        'params': {'reg_alpha': [0]}
    },
    'lightgbm': {
        'name': 'üí° LightGBM (CPU-Optimis√©)',
        'model': lgb.LGBMClassifier(
            n_estimators=100,
            learning_rate=0.1,
            num_leaves=31,
            n_jobs=4,
            random_state=RANDOM_STATE,
            verbose=-1
        ),
        'params': {'reg_alpha': [0]}  # Minimal grid
    }
}

# ===== ENTRA√éNER =====
results = {}
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

print("ü§ñ ENTRA√éNEMENT\n")
for key, info in tqdm(models_config.items(), desc="Mod√®les", unit="model"):
    try:
        print(f"\n{info['name']}", end=" ")
        
        grid_search = GridSearchCV(
            estimator=info['model'],
            param_grid=info['params'],
            cv=2,
            scoring='roc_auc',
            n_jobs=1,
            verbose=0
        )
        
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_
        
        y_pred = best_model.predict(X_test)
        y_pred_proba = best_model.predict_proba(X_test)[:, 1]
        
        accuracy = accuracy_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_pred_proba)
        
        model_path = os.path.join(MODELS_DIR, f"{key}_{timestamp}.pkl")
        joblib.dump(best_model, model_path)
        
        results[key] = {'accuracy': accuracy, 'auc': auc}
        
        print(f"‚úÖ Acc={accuracy:.4f} | AUC={auc:.4f}")
        
    except Exception as e:
        print(f"‚ùå Erreur: {str(e)[:60]}")

# ===== R√âSUM√â =====
print("\n" + "="*70)
print("üìä R√âSUM√â FINAL")
print("="*70 + "\n")

for name, metrics in sorted(results.items(), key=lambda x: x[1]['auc'], reverse=True):
    print(f"{name:20} | Accuracy: {metrics['accuracy']:.4f} | AUC: {metrics['auc']:.4f}")

print("\n" + "="*70)
print(f"‚úÖ ENTRA√éNEMENT TERMIN√â!")
print(f"üìÅ Mod√®les: {os.path.abspath(MODELS_DIR)}")
print("="*70 + "\n")
