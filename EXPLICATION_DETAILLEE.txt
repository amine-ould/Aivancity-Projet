"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         EXPLICATION DU CODE - PIPELINE D'ENTRAÃNEMENT ML                   â•‘
â•‘              PrÃ©diction de dÃ©faillances industrielles                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ TABLE DES MATIÃˆRES:
  1. Structure gÃ©nÃ©rale du projet
  2. Les 3 problÃ¨mes corrigÃ©s
  3. Flux complet d'entraÃ®nement
  4. DÃ©tails de chaque Ã©tape
  5. Comment utiliser le code
  6. ParamÃ¨tres Ã  modifier


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1ï¸âƒ£  STRUCTURE GÃ‰NÃ‰RALE DU PROJET
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

data/
â”œâ”€â”€ raw/                          â† Fichiers CSV bruts (ğŸ“¥ EntrÃ©e)
â”‚   â”œâ”€â”€ sensor_data.csv           â† DonnÃ©es des capteurs (temp, vibration, etc.)
â”‚   â””â”€â”€ failure_logs.csv          â† Journaux des dÃ©faillances
â”‚
â””â”€â”€ processed/                    â† DonnÃ©es traitÃ©es (intermÃ©diaires)
    â”œâ”€â”€ extracted_data/           â† AprÃ¨s extraction.py
    â”œâ”€â”€ cleaned_data/             â† AprÃ¨s clean.py âš ï¸ C'EST ICI VOTRE DATA!
    â””â”€â”€ augmented_data/           â† AprÃ¨s augmentation


src/
â”œâ”€â”€ data/                         â† Ã‰TAPE 1: PRÃ‰PARATION
â”‚   â”œâ”€â”€ extract.py               â†’ Charger CSV bruts
â”‚   â”œâ”€â”€ clean.py                 â†’ Nettoyer (NaN, outliers, doublons)
â”‚   â””â”€â”€ augment.py               â†’ Augmenter les donnÃ©es (optionnel)
â”‚
â”œâ”€â”€ features/                     â† Ã‰TAPE 2: FEATURES ENGINEERING
â”‚   â””â”€â”€ build_features.py        â†’ CrÃ©er variables polynomiales, cycles
â”‚
â”œâ”€â”€ models/                       â† Ã‰TAPE 3 & 4: ENTRAÃNEMENT â­ C'EST ICI!
â”‚   â”œâ”€â”€ train_model.py           â†’ CLASSE ModelTrainer (entraÃ®ne les modÃ¨les)
â”‚   â”œâ”€â”€ evaluation.py            â†’ Ã‰valuation dÃ©taillÃ©e
â”‚   â”œâ”€â”€ predict_model.py         â†’ Utiliser modÃ¨les pour prÃ©dictions
â”‚   â””â”€â”€ models/                  â† ModÃ¨les sauvegardÃ©s (.pkl)
â”‚
â””â”€â”€ monitoring/                   â† Ã‰TAPE 5: SUIVI
    â”œâ”€â”€ data_drift.py            â†’ DÃ©tecter changements dans donnÃ©es
    â””â”€â”€ performance_tracking.py  â†’ Suivi des performances

tests/                            â† Tests unitaires
wandb/                            â† Tracking (Weights & Biases)
run_training.py                   â† âœ… SCRIPT SIMPLE Ã€ LANCER!


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
2ï¸âƒ£  LES 3 PROBLÃˆMES CORRIGÃ‰S
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… PROBLÃˆME #1: Dictionnaire de modÃ¨les VIDE (ligne ~96)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   AVANT (code cassÃ©):
   â”Œâ”€ self.models = {
   â”‚              }  â† VIDE! Aucun modÃ¨le Ã  entraÃ®ner
   â””â”€
   
   APRÃˆS (code corrigÃ©):
   â”Œâ”€ self.models = {
   â”‚    'random_forest': {...},       â† Random Forest
   â”‚    'gradient_boosting': {...},   â† Gradient Boosting
   â”‚    'logistic_regression': {...}, â† RÃ©gression logistique
   â”‚    'xgboost': {...},             â† XGBoost
   â”‚    'lightgbm': {...}             â† LightGBM
   â””â”€ }


âœ… PROBLÃˆME #2: MÃ©triques d'Ã©valuation INCOMPLÃˆTES (ligne ~238)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   AVANT (code cassÃ©):
   â”Œâ”€ accuracy = 
   â”‚ conf_matrix = 
   â”‚ class_report = 
   â”‚ auc_score =      â† TOUS VIDES! (juste "=" sans valeur)
   â””â”€
   
   APRÃˆS (code corrigÃ©):
   â”Œâ”€ accuracy = (y_pred == y_test).astype(int).mean()
   â”‚ conf_matrix = confusion_matrix(y_test, y_pred)
   â”‚ class_report = classification_report(y_test, y_pred)
   â”‚ auc_score = roc_auc_score(y_test, y_pred_proba)
   â””â”€
   
   â¡ï¸  Maintenant on calcule VRAIMENT les mÃ©triques!


âœ… PROBLÃˆME #3: Fonction find_best_model() CASSÃ‰E
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   AVANT (code cassÃ©):
   â”Œâ”€ scores = 
   â”‚ best_model = 
   â”‚ logger.info(f"Meilleur: {best_model}...")  â† Utilise variable vide!
   â””â”€
   
   APRÃˆS (code corrigÃ©):
   â”Œâ”€ scores = {model: eval_info[metric] 
   â”‚            for model, eval_info in evaluation_results.items()}
   â”‚ best_model = max(scores, key=scores.get)
   â””â”€
   
   â¡ï¸  Trouve vraiment le meilleur modÃ¨le!


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
3ï¸âƒ£  FLUX COMPLET D'ENTRAÃNEMENT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Voici ce qui se passe quand vous lancez train_model.py:


â”Œâ”€ Ã‰TAPE 1: CRÃ‰ER L'ENTRAÃNEUR (ModelTrainer)
â”‚  â”œâ”€ Charge les paramÃ¨tres (chemin data, rÃ©pertoire modÃ¨les, etc.)
â”‚  â”œâ”€ CrÃ©e le dictionnaire des 5 modÃ¨les avec leurs hyperparamÃ¨tres
â”‚  â””â”€ CrÃ©e dossier src/models/models/ pour sauvegarder
â”‚
â”œâ”€ Ã‰TAPE 2: CHARGER LES DONNÃ‰ES
â”‚  â”œâ”€ Lit le fichier CSV nettoyÃ© (cleaned_data.csv)
â”‚  â”œâ”€ Convertit en DataFrame Pandas
â”‚  â”œâ”€ Affiche: "DonnÃ©es chargÃ©es: 50000 lignes x 45 colonnes"
â”‚  â””â”€ VÃ©rifie pas de problÃ¨mes
â”‚
â”œâ”€ Ã‰TAPE 3: PRÃ‰PARER TRAIN/TEST
â”‚  â”œâ”€ SÃ©pare: X (features) et y (target=failure_within_24h)
â”‚  â”œâ”€ Split 80/20: 
â”‚  â”‚  â”œâ”€ X_train: 40000 lignes (entraÃ®nement)
â”‚  â”‚  â””â”€ X_test:  10000 lignes (Ã©valuation)
â”‚  â”œâ”€ Nettoie NaN/Inf â†’ remplace par 0
â”‚  â””â”€ Affiche distribution: "Classe 0: 60%, Classe 1: 40%"
â”‚
â”œâ”€ Ã‰TAPE 4: ENTRAÃNER LES MODÃˆLES â­ (cÅ“ur du code)
â”‚  â”œâ”€ Pour chaque modÃ¨le (Random Forest, XGBoost, ...):
â”‚  â”‚  â”œâ”€ Utilise GridSearchCV pour tester 50+ combinaisons
â”‚  â”‚  â”‚  ex: RF avec n_estimators=[100, 200], max_depth=[10, 20, 30]
â”‚  â”‚  â”œâ”€ Utilise 5-fold cross-validation (valide 5 fois)
â”‚  â”‚  â”œâ”€ Affiche: "Meilleurs paramÃ¨tres: n_estimators=200, max_depth=20"
â”‚  â”‚  â””â”€ Garde le meilleur modÃ¨le trouvÃ©
â”‚  â””â”€ "EntraÃ®nement terminÃ©: 5 modÃ¨les entraÃ®nÃ©s"
â”‚
â”œâ”€ Ã‰TAPE 5: Ã‰VALUER SUR TEST SET
â”‚  â”œâ”€ Pour chaque modÃ¨le entraÃ®nÃ©:
â”‚  â”‚  â”œâ”€ Fait prÃ©dictions sur X_test
â”‚  â”‚  â”œâ”€ Calcule 4 mÃ©triques:
â”‚  â”‚  â”‚  â”œâ”€ Accuracy: combien prÃ©dictions justes? (0-1)
â”‚  â”‚  â”‚  â”œâ”€ Confusion Matrix: TP, FP, TN, FN
â”‚  â”‚  â”‚  â”œâ”€ Classification Report: prÃ©cision, rappel, F1
â”‚  â”‚  â”‚  â””â”€ AUC: courbe ROC (0-1, plus haut = meilleur)
â”‚  â”‚  â””â”€ Affiche rÃ©sumÃ©
â”‚  â””â”€
â”‚
â”œâ”€ Ã‰TAPE 6: SAUVEGARDER MODÃˆLES
â”‚  â”œâ”€ Pour chaque modÃ¨le:
â”‚  â”‚  â”œâ”€ CrÃ©e dictionnaire avec:
â”‚  â”‚  â”‚  â”œâ”€ model: le modÃ¨le entraÃ®nÃ©
â”‚  â”‚  â”‚  â”œâ”€ parameters: meilleurs hyperparamÃ¨tres
â”‚  â”‚  â”‚  â”œâ”€ cv_score: score en validation croisÃ©e
â”‚  â”‚  â”‚  â”œâ”€ evaluation: rÃ©sultats sur test
â”‚  â”‚  â”‚  â””â”€ timestamp: date/heure
â”‚  â”‚  â”œâ”€ Sauvegarde en .pkl (format binaire)
â”‚  â”‚  â”‚  ex: "random_forest_20250114_143022.pkl"
â”‚  â”‚  â””â”€ Affiche: "ModÃ¨le sauvegardÃ© Ã  src/models/models/..."
â”‚  â”‚
â”‚  â””â”€ CrÃ©e fichier rÃ©sumÃ©:
â”‚     â””â”€ "training_summary_20250114_143022.pkl"
â”‚
â”œâ”€ Ã‰TAPE 7: SAUVEGARDER L'IMPORTANCE DES FEATURES
â”‚  â”œâ”€ Pour modÃ¨les avec feature_importances_ (RF, XGB, LGB):
â”‚  â”‚  â”œâ”€ Extrait importance de chaque variable
â”‚  â”‚  â”œâ”€ CrÃ©e DataFrame triÃ© par importance
â”‚  â”‚  â”œâ”€ Sauvegarde CSV: "random_forest_feature_importance_*.csv"
â”‚  â”‚  â””â”€ Affiche: "Top 20 features sauvegardÃ©es"
â”‚  â””â”€
â”‚
â””â”€ âœ… ENTRAÃNEMENT TERMINÃ‰!
   â”œâ”€ "5 modÃ¨les sauvegardÃ©s dans src/models/models/"
   â””â”€ "Utilisez predict_model.py pour prÃ©dictions"


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
4ï¸âƒ£  DÃ‰TAILS DE CHAQUE Ã‰TAPE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ load_data() - Charger les donnÃ©es
â”‚
â”‚  EntrÃ©e: data_path = "data/processed/cleaned_data/sensor_data.csv"
â”‚
â”‚  Processus:
â”‚    df = pd.read_csv(data_path)
â”‚    return df  # DataFrame de 50000 x 45
â”‚
â”‚  Sortie: DataFrame Pandas avec colonnes:
â”‚    - temperature, vibration, pressure, current, ... (features)
â”‚    - failure_within_24h (target: 0 ou 1)
â”‚


â”œâ”€ prepare_train_test_data() - SÃ©parer en train/test
â”‚
â”‚  EntrÃ©e: data (DataFrame), target_column="failure_within_24h"
â”‚
â”‚  Processus:
â”‚    X = data.drop(columns=['failure_within_24h'])  # Features
â”‚    y = data['failure_within_24h']                  # Target
â”‚    X_train, X_test, y_train, y_test = train_test_split(
â”‚        X, y, test_size=0.2, random_state=42, stratify=y
â”‚    )
â”‚
â”‚  Sortie: 4 DataFrames/Series
â”‚    - X_train: 40000 x 45 (80% des donnÃ©es)
â”‚    - X_test:  10000 x 45 (20% des donnÃ©es)
â”‚    - y_train: 40000 labels (0 ou 1)
â”‚    - y_test:  10000 labels (0 ou 1)
â”‚


â”œâ”€ train_models() - EntraÃ®ner les modÃ¨les
â”‚
â”‚  EntrÃ©e: X_train, y_train, models_to_train=None, cv=5
â”‚
â”‚  Processus pour chaque modÃ¨le:
â”‚
â”‚    # 1. Initialiser modÃ¨le et hyperparamÃ¨tres
â”‚    model = RandomForestClassifier()
â”‚    params = {
â”‚        'n_estimators': [100, 200, 300],
â”‚        'max_depth': [None, 10, 20, 30],
â”‚        'min_samples_split': [2, 5, 10]
â”‚    }
â”‚    # â¡ï¸ 3 Ã— 4 Ã— 3 = 36 combinaisons Ã  tester!
â”‚
â”‚    # 2. GridSearchCV teste TOUTES les combinaisons
â”‚    grid_search = GridSearchCV(model, params, cv=5)
â”‚    grid_search.fit(X_train, y_train)
â”‚    # â¡ï¸ Pour chaque combinaison, valide 5 fois (5-fold CV)
â”‚    # â¡ï¸ Total: 36 combinaisons Ã— 5 folds = 180 entraÃ®nements!
â”‚
â”‚    # 3. Garder le meilleur
â”‚    best_model = grid_search.best_estimator_
â”‚    best_params = grid_search.best_params_
â”‚    best_score = grid_search.best_score_
â”‚    # â¡ï¸ Meilleur score: 0.8934 (AUC)
â”‚
â”‚  Sortie: Dict avec modÃ¨les entraÃ®nÃ©s
â”‚    {
â”‚      'random_forest': {'model': ..., 'params': {...}, 'cv_score': 0.8934},
â”‚      'xgboost': {'model': ..., 'params': {...}, 'cv_score': 0.9124},
â”‚      ...
â”‚    }
â”‚


â”œâ”€ evaluate_models() - Ã‰valuer sur TEST set
â”‚
â”‚  EntrÃ©e: trained_models, X_test, y_test
â”‚
â”‚  Processus pour chaque modÃ¨le:
â”‚
â”‚    # 1. Faire prÃ©dictions
â”‚    y_pred = model.predict(X_test)  # 0 ou 1 pour chaque exemple
â”‚    y_pred_proba = model.predict_proba(X_test)[:, 1]  # ProbabilitÃ©s
â”‚    # â¡ï¸ y_pred = [0, 1, 1, 0, 1, ...]  (10000 prÃ©dictions)
â”‚    # â¡ï¸ y_pred_proba = [0.2, 0.8, 0.7, 0.1, 0.9, ...]  (confiance)
â”‚
â”‚    # 2. Calculer mÃ©triques
â”‚    accuracy = (y_pred == y_test).mean()  # 89.2%
â”‚    conf_matrix = confusion_matrix(y_test, y_pred)
â”‚    # â¡ï¸ [[TN, FP],
â”‚    #      [FN, TP]]
â”‚    class_report = classification_report(y_test, y_pred)
â”‚    auc_score = roc_auc_score(y_test, y_pred_proba)  # 0.914
â”‚
â”‚  Sortie: Dict avec performances
â”‚    {
â”‚      'random_forest': {
â”‚          'accuracy': 0.8932,
â”‚          'auc': 0.9234,
â”‚          'confusion_matrix': [[...], [...]],
â”‚          'classification_report': '...'
â”‚      },
â”‚      ...
â”‚    }
â”‚


â”œâ”€ save_models() - Sauvegarder les modÃ¨les
â”‚
â”‚  EntrÃ©e: trained_models, evaluation_results, features_info
â”‚
â”‚  Processus:
â”‚    timestamp = "20250114_143022"
â”‚    
â”‚    Pour chaque modÃ¨le:
â”‚      model_data = {
â”‚          'model': model_entraÃ®nÃ©,  # L'objet Python entraÃ®nÃ©
â”‚          'parameters': {...},      # Meilleurs paramÃ¨tres
â”‚          'cv_score': 0.8934,       # Score en cross-validation
â”‚          'evaluation': {...},      # RÃ©sultats sur test
â”‚          'features_info': {...},   # Noms des colonnes
â”‚          'timestamp': timestamp    # Quand entraÃ®nÃ©
â”‚      }
â”‚      
â”‚      # Sauvegarder en fichier binaire
â”‚      with open(f"{model_name}_{timestamp}.pkl", 'wb') as f:
â”‚          pickle.dump(model_data, f)
â”‚      # â¡ï¸ Fichier crÃ©Ã©: "random_forest_20250114_143022.pkl" (~10 MB)
â”‚
â”‚  Sortie: Fichiers .pkl dans src/models/models/
â”‚


â””â”€ save_feature_importance() - Importance des features
  
   EntrÃ©e: trained_models, feature_names
   
   Processus pour chaque modÃ¨le:
     
     importances = model.feature_importances_  # Poids de chaque feature
     importance_df = DataFrame({
         'feature': ['temperature', 'vibration', ...],
         'importance': [0.25, 0.18, ...]
     })
     importance_df.to_csv(f"{model_name}_feature_importance_*.csv")
     
     â¡ï¸ Tableau triÃ© par importance (le plus important en haut)
   
   Sortie: Fichiers CSV avec top 20 features
     
     Exemple:
     feature,importance
     temperature,0.2543
     pressure,0.1876
     vibration,0.1234
     ...


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
5ï¸âƒ£  COMMENT UTILISER LE CODE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OPTION A - Utiliser le script simple âœ… RECOMMANDÃ‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Ouvrir run_training.py
2. Ã‰diter ces lignes:
   
   DATA_PATH = "votre/chemin/cleaned_data.csv"
   MODELS_TO_TRAIN = None  # ou ["random_forest", "xgboost"]
   
3. Lancer:
   python run_training.py

4. Attendre 10-30 minutes
5. RÃ©sultats dans src/models/models/


OPTION B - Ligne de commande avancÃ©e
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python -m src.models.train_model \
    --data_path "data/processed/cleaned_data.csv" \
    --target_column "failure_within_24h" \
    --test_size 0.2 \
    --models random_forest xgboost


OPTION C - Code Python (pour Jupyter/IDE)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from src.models.train_model import train_and_evaluate

trainer, models, results, paths = train_and_evaluate(
    data_path="data/processed/cleaned_data.csv",
    target_column="failure_within_24h",
    models_to_train=["random_forest", "xgboost"],
    cv=5
)

print(results)  # Voir les performances
print(paths)    # Voir oÃ¹ modÃ¨les sauvegardÃ©s


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
6ï¸âƒ£  PARAMÃˆTRES Ã€ MODIFIER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Dans run_training.py, modifiez:

â”Œâ”€ DATA_PATH âš ï¸ OBLIGATOIRE
â”‚  Description: Chemin vers fichier CSV nettoyÃ©
â”‚  Exemple: r"data\processed\cleaned_data\sensor_data_cleaned.csv"
â”‚  DÃ©faut: Doit pointer vers fichier existant
â”‚
â”œâ”€ TEST_SIZE
â”‚  Description: % de donnÃ©es pour Ã©valuation
â”‚  Valeur: Entre 0.1 et 0.4 (0.2 = 20%)
â”‚  DÃ©faut: 0.2 (80% train, 20% test)
â”‚  â¡ï¸ Plus petit = plus d'entraÃ®nement, moins d'Ã©valuation
â”‚
â”œâ”€ TARGET_COLUMN
â”‚  Description: Nom colonne Ã  prÃ©dire
â”‚  Valeur: Doit Ãªtre 0 ou 1 (classification binaire)
â”‚  DÃ©faut: "failure_within_24h"
â”‚  â¡ï¸ VÃ©rifiez que cette colonne existe dans CSV!
â”‚
â”œâ”€ MODELS_TO_TRAIN
â”‚  Description: Quels modÃ¨les entraÃ®ner
â”‚  Options: ["random_forest", "gradient_boosting", "logistic_regression", 
â”‚            "xgboost", "lightgbm"]
â”‚  DÃ©faut: None (entraÃ®ne TOUS)
â”‚  Exemple: ["random_forest", "xgboost"]  # Plus rapide
â”‚  â¡ï¸ None = entraÃ®ne tous, plus long mais meilleur comparaison
â”‚
â”œâ”€ RANDOM_STATE
â”‚  Description: Graine alÃ©atoire
â”‚  Valeur: N'importe quel entier (42 classique)
â”‚  DÃ©faut: 42
â”‚  â¡ï¸ Permet de reproduire rÃ©sultats exactement
â”‚
â”œâ”€ CV
â”‚  Description: K-fold cross-validation
â”‚  Valeur: Entre 3 et 10 (5 classique)
â”‚  DÃ©faut: 5
â”‚  â¡ï¸ Plus haut = plus lent mais meilleure Ã©valuation


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          RÃ‰SUMÃ‰ EN UNE PHRASE                             â•‘
â•‘                                                                            â•‘
â•‘  train_model.py ENTRAÃNE 5 MODÃˆLES DIFFÃ‰RENTS SUR VOS DONNÃ‰ES NETTOYÃ‰ES,  â•‘
â•‘  LES Ã‰VALUE SUR UN TEST SET, ET SAUVEGARDE LES MEILLEURS AVEC LEURS       â•‘
â•‘  MÃ‰TRIQUES ET L'IMPORTANCE DES FEATURES.                                  â•‘
â•‘                                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PrÃªt? Lancez: python run_training.py ğŸš€

"""
